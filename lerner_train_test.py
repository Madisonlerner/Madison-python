# -*- coding: utf-8 -*-
"""Lerner-Train_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AxAaCQ8jamFTM7oRDAyOlcRgRX1QSvOx
"""

!pip install scikit-learn

"""### Split a dataset into training and testing sets"""

# Commented out IPython magic to ensure Python compatibility.
#Imports
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

"""

- Independent variables or attributes: `X`
- Dependent variable or target: `y`.
"""

from sklearn.datasets import load_iris

iris = load_iris()
X, y = iris.data, iris.target

from sklearn.utils import shuffle
X
y
X, y = shuffle(X, y)

"""### The Target Variable X is a prediction of what kind of flower class the observation belongs to.      
Class 0: Setosa      
Class 1: Versicolor      
Class 1: Virginica  

Since our data is sorted ascending by class, we do not want to end up in a situation where the training dataset contains only 0 and 1 labels, while the test only contains Virginica (class 2). Hence, we should **randomly shuffle the dataset before we split the dataset**.

### Split the data into training and testing.

- scikit-learn package comprises a pre-built function to split data into training and testing sets.
- Here, we use 50% of the data as training, and 50% testing.
"""

#Import Module
from sklearn.model_selection import train_test_split


train_X, test_X, train_y, test_y = train_test_split(X, y,
                                                    train_size=0.5,
                                                    test_size=0.5,
                                                    random_state=122)
print("Labels for training and testing data")
print(train_y)
print(test_y)

"""---

## Logistic Regression: Classification

---
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

classifier = LogisticRegression(max_iter=10000, random_state=0)
classifier.fit(train_X, train_y)

prediction = classifier.predict(test_X)

print(prediction)
print(test_y)

"""## Performance Metric: Accuracy"""

acc = accuracy_score(test_y, classifier.predict(test_X)) * 100
accuracy = accuracy_score(test_y, prediction) * 100
print(f"Logistic Regression model accuracy: {accuracy:.2f}%")

"""### Alternative Ways of Calculating the accuracy."""

np.mean(prediction == test_y)
classifier.score(test_X, test_y)

# performance on the training set
classifier.score(train_X, train_y)

"""## Now, try 80% and 20% split."""

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets with 80% for training and 20% for testing
train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=122)

# Print labels for training and testing data to verify the split
print("Labels for training and testing data:")
print(train_y)
print(test_y)

"""## K Nearest Neighbors"""

from sklearn.neighbors import KNeighborsClassifier

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Create KNN classifier with k=3
# knn = KNeighborsClassifier(n_neighbors=3)

# Set a parameter for how many nearest neighbors you want to examine.
knn = KNeighborsClassifier(n_neighbors=1) # only 1 neighbor

# Train the model
knn.fit(X_train, y_train)

# Predict on the test set
y_pred = knn.predict(X_test)

# Evaluate the model
accuracy = 100*accuracy_score(y_test, y_pred)
print(f"kNN Accuracy: {accuracy}")

from sklearn.neighbors import KNeighborsClassifier

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=70)

# Create KNN classifier with k=3
# knn = KNeighborsClassifier(n_neighbors=3)

# Set a parameter for how many nearest neighbors you want to examine.
knn = KNeighborsClassifier(n_neighbors=1) # only 1 neighbor

# Train the model
knn.fit(X_train, y_train)

# Predict on the test set
y_pred = knn.predict(X_test)

# Evaluate the model
accuracy = 100*accuracy_score(y_test, y_pred)
print(f"kNN Accuracy: {accuracy}")

"""## Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics

# Split the dataset into training and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Create Decision Tree classifer object
classifier = DecisionTreeClassifier()

# Train Decision Tree Classifer
classifier = classifier.fit(X_train,y_train)
y_pred = classifier.predict(X_test) # predict

# Model Accuracy
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print('Accuracy:',classifier.score(X_test, y_test))

"""## Performance Metrics"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))





